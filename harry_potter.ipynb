{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeepsMaxi305/Data_Science/blob/main/harry_potter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f78b699a",
      "metadata": {
        "id": "f78b699a"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdfe7ada",
      "metadata": {
        "id": "bdfe7ada"
      },
      "source": [
        "You should process some texts using [NLTK](https://www.nltk.org/) or [spaCy](https://spacy.io/) libraries (ideally both). In particular, you should do the following:\n",
        "- Load the `harry_potter` book. You can find this text corpus in the datasets folder.\n",
        "- Segment the text of the book into sentences. How many sentences does this book have?\n",
        "- Compute the frequency of each token in the book. What are the most frequent tokens?\n",
        "- Choose a sentence from the book. Analyze this chosen sentence by\n",
        "    - Calculating all [n-grams](https://en.wikipedia.org/wiki/N-gram).\n",
        "    - Finding [POS tags](https://en.wikipedia.org/wiki/Part-of-speech_tagging) of tokens.\n",
        "    - [Stemming](https://en.wikipedia.org/wiki/Stemming) and [lemmatizing](https://en.wikipedia.org/wiki/Lemmatisation) tokens.\n",
        "- Check the documentation to identify the most important hyperparameters, attributes, and methods. Use them in practice."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxL1f2z8GINV",
        "outputId": "e36f3f8d-9677-4d32-e91e-0e573a8ea06f"
      },
      "id": "kxL1f2z8GINV",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting textacy\n",
            "  Downloading textacy-0.13.0-py3-none-any.whl (210 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jellyfish>=0.8.0\n",
            "  Downloading jellyfish-0.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from textacy) (5.3.0)\n",
            "Requirement already satisfied: catalogue~=2.0 in /usr/local/lib/python3.9/dist-packages (from textacy) (2.0.8)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.9/dist-packages (from textacy) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.9/dist-packages (from textacy) (1.10.1)\n",
            "Requirement already satisfied: tqdm>=4.19.6 in /usr/local/lib/python3.9/dist-packages (from textacy) (4.65.0)\n",
            "Collecting cytoolz>=0.10.1\n",
            "  Downloading cytoolz-0.12.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.9/dist-packages (from textacy) (1.22.4)\n",
            "Requirement already satisfied: networkx>=2.7 in /usr/local/lib/python3.9/dist-packages (from textacy) (3.1)\n",
            "Requirement already satisfied: spacy~=3.0 in /usr/local/lib/python3.9/dist-packages (from textacy) (3.5.2)\n",
            "Requirement already satisfied: joblib>=0.13.0 in /usr/local/lib/python3.9/dist-packages (from textacy) (1.2.0)\n",
            "Collecting pyphen>=0.10.0\n",
            "  Downloading pyphen-0.14.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting floret~=0.10.0\n",
            "  Downloading floret-0.10.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (312 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.7/312.7 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.9/dist-packages (from textacy) (2.27.1)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from cytoolz>=0.10.1->textacy) (0.12.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.10.0->textacy) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.10.0->textacy) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.10.0->textacy) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.10.0->textacy) (2.0.12)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0->textacy) (3.1.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy~=3.0->textacy) (3.1.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy~=3.0->textacy) (1.0.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy~=3.0->textacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy~=3.0->textacy) (23.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy~=3.0->textacy) (1.10.7)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy~=3.0->textacy) (8.1.9)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy~=3.0->textacy) (0.7.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy~=3.0->textacy) (3.0.8)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy~=3.0->textacy) (2.0.7)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy~=3.0->textacy) (1.1.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy~=3.0->textacy) (3.3.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy~=3.0->textacy) (3.0.12)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy~=3.0->textacy) (0.10.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy~=3.0->textacy) (1.0.4)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy~=3.0->textacy) (2.4.6)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy~=3.0->textacy) (6.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy~=3.0->textacy) (4.5.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy~=3.0->textacy) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy~=3.0->textacy) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy~=3.0->textacy) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy~=3.0->textacy) (2.1.2)\n",
            "Installing collected packages: pyphen, jellyfish, floret, cytoolz, textacy\n",
            "Successfully installed cytoolz-0.12.1 floret-0.10.2 jellyfish-0.11.2 pyphen-0.14.0 textacy-0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries"
      ],
      "metadata": {
        "id": "BmeoPhpsIapX"
      },
      "id": "BmeoPhpsIapX"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a8d7e3f0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8d7e3f0",
        "outputId": "6b170d0c-7c67-461b-f7d2-747f898f88a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: textacy in /usr/local/lib/python3.9/dist-packages (0.13.0)\n",
            "Requirement already satisfied: networkx>=2.7 in /usr/local/lib/python3.9/dist-packages (from textacy) (3.1)\n",
            "Requirement already satisfied: catalogue~=2.0 in /usr/local/lib/python3.9/dist-packages (from textacy) (2.0.8)\n",
            "Requirement already satisfied: tqdm>=4.19.6 in /usr/local/lib/python3.9/dist-packages (from textacy) (4.65.0)\n",
            "Requirement already satisfied: jellyfish>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from textacy) (0.11.2)\n",
            "Requirement already satisfied: joblib>=0.13.0 in /usr/local/lib/python3.9/dist-packages (from textacy) (1.2.0)\n",
            "Requirement already satisfied: floret~=0.10.0 in /usr/local/lib/python3.9/dist-packages (from textacy) (0.10.2)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.9/dist-packages (from textacy) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.9/dist-packages (from textacy) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.9/dist-packages (from textacy) (1.22.4)\n",
            "Requirement already satisfied: cachetools>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from textacy) (5.3.0)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.9/dist-packages (from textacy) (2.27.1)\n",
            "Requirement already satisfied: spacy~=3.0 in /usr/local/lib/python3.9/dist-packages (from textacy) (3.5.2)\n",
            "Requirement already satisfied: pyphen>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from textacy) (0.14.0)\n",
            "Requirement already satisfied: cytoolz>=0.10.1 in /usr/local/lib/python3.9/dist-packages (from textacy) (0.12.1)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from cytoolz>=0.10.1->textacy) (0.12.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.10.0->textacy) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.10.0->textacy) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.10.0->textacy) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.10.0->textacy) (3.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0->textacy) (3.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy~=3.0->textacy) (23.1)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy~=3.0->textacy) (0.7.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy~=3.0->textacy) (2.4.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy~=3.0->textacy) (3.0.8)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy~=3.0->textacy) (1.10.7)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy~=3.0->textacy) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy~=3.0->textacy) (1.1.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy~=3.0->textacy) (3.0.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy~=3.0->textacy) (3.1.2)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy~=3.0->textacy) (0.10.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy~=3.0->textacy) (67.7.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy~=3.0->textacy) (6.3.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy~=3.0->textacy) (1.0.4)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy~=3.0->textacy) (3.3.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy~=3.0->textacy) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy~=3.0->textacy) (2.0.7)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy~=3.0->textacy) (4.5.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy~=3.0->textacy) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy~=3.0->textacy) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy~=3.0->textacy) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy~=3.0->textacy) (2.1.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "!pip install textacy\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "import spacy\n",
        "import textacy\n",
        "nlp = spacy.load('en_core_web_sm')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading Harry Potter Book"
      ],
      "metadata": {
        "id": "EhPUn_l8ISoz"
      },
      "id": "EhPUn_l8ISoz"
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"/content/harry_potter.txt\")\n",
        "text = f.read()\n",
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysLAlXnlG-ir",
        "outputId": "bb3638ad-29d2-4422-e64b-12162806f0d5"
      },
      "id": "ysLAlXnlG-ir",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CHAPTER ONE THE BOY WHO LIVED \n",
            "\n",
            "Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense. \n",
            "\n",
            "Mr. Dursley was the director of a firm called Grunnings, which made drills. He was a big, beefy man with hardly any neck, although he did have a very large mustache. Mrs. Dursley was thin and blonde and had nearly twice the usual amount of neck, which came in very useful as she spent so much of her time craning over garden fences, spying on the neighbors. The Dursleys had a small son called Dudley and in their opinion there was no finer boy anywhere. \n",
            "\n",
            "The Dursleys had everything they wanted, but they also had a secret, and their greatest fear was that somebody would discover it. They didn't think they could bear it if anyone found out about the Potters. Mrs. Potter was Mrs. Dursley's sister, b\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sentence Segmentation"
      ],
      "metadata": {
        "id": "DcP1oSSoIDAq"
      },
      "id": "DcP1oSSoIDAq"
    },
    {
      "cell_type": "code",
      "source": [
        "nltk_sentences = nltk.sent_tokenize(text)\n",
        "len(nltk_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqBxksaQIFoO",
        "outputId": "a1afbfb8-b674-4183-ed21-6ba7e33cf0d7"
      },
      "id": "BqBxksaQIFoO",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6394"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk_sentences[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "fzc33R2vIRNs",
        "outputId": "03fe5757-7a70-4147-a458-85c5ba898dba"
      },
      "id": "fzc33R2vIRNs",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'CHAPTER ONE THE BOY WHO LIVED \\n\\nMr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(text)\n",
        "spacy_sentences = list(doc.sents)\n",
        "len(spacy_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3j48-PPIW46",
        "outputId": "4e69dd7b-4682-4e4e-949d-744ecd4bb736"
      },
      "id": "U3j48-PPIW46",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6186"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spacy_sentences[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHNg46bYIz5i",
        "outputId": "956e2953-10df-4590-f4f6-57913c8a4950"
      },
      "id": "mHNg46bYIz5i",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CHAPTER ONE THE BOY WHO LIVED \n",
              "\n",
              "Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much."
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Word Tokenization"
      ],
      "metadata": {
        "id": "ZnjyoF6tJDDQ"
      },
      "id": "ZnjyoF6tJDDQ"
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = {}\n",
        "for s in nltk_sentences:\n",
        "    sentence_tokens = nltk.tokenize.word_tokenize(s)\n",
        "    for t in sentence_tokens:\n",
        "        if t not in tokens:\n",
        "            tokens[t] = 0\n",
        "        tokens[t] +=1\n",
        "\n",
        "frequent_tokens = sorted(tokens, key=tokens.get, reverse =True)[:20]\n",
        "for t in frequent_tokens:\n",
        "    print(t,\"\\t\\t\\t\\t\", tokens[t])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPMq5uzgJFgX",
        "outputId": "9e39ad27-a770-4b40-f436-4366cb6330e6"
      },
      "id": "GPMq5uzgJFgX",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ", \t\t\t\t 5658\n",
            ". \t\t\t\t 5119\n",
            "the \t\t\t\t 3310\n",
            "'' \t\t\t\t 2441\n",
            "`` \t\t\t\t 2307\n",
            "to \t\t\t\t 1845\n",
            "and \t\t\t\t 1804\n",
            "a \t\t\t\t 1578\n",
            "Harry \t\t\t\t 1323\n",
            "was \t\t\t\t 1253\n",
            "of \t\t\t\t 1242\n",
            "he \t\t\t\t 1208\n",
            "'s \t\t\t\t 997\n",
            "in \t\t\t\t 933\n",
            "I \t\t\t\t 919\n",
            "it \t\t\t\t 897\n",
            "his \t\t\t\t 896\n",
            "you \t\t\t\t 837\n",
            "n't \t\t\t\t 826\n",
            "said \t\t\t\t 793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBNaa97LK0xg",
        "outputId": "6d8e4841-95e2-4ebc-e9d1-19a022c9a013"
      },
      "id": "LBNaa97LK0xg",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'CHAPTER': 17,\n",
              " 'ONE': 2,\n",
              " 'THE': 18,\n",
              " 'BOY': 1,\n",
              " 'WHO': 1,\n",
              " 'LIVED': 1,\n",
              " 'Mr.': 79,\n",
              " 'and': 1804,\n",
              " 'Mrs.': 44,\n",
              " 'Dursley': 54,\n",
              " ',': 5658,\n",
              " 'of': 1242,\n",
              " 'number': 15,\n",
              " 'four': 30,\n",
              " 'Privet': 16,\n",
              " 'Drive': 16,\n",
              " 'were': 330,\n",
              " 'proud': 7,\n",
              " 'to': 1845,\n",
              " 'say': 72,\n",
              " 'that': 632,\n",
              " 'they': 506,\n",
              " 'perfectly': 5,\n",
              " 'normal': 10,\n",
              " 'thank': 4,\n",
              " 'you': 837,\n",
              " 'very': 161,\n",
              " 'much': 74,\n",
              " '.': 5119,\n",
              " 'They': 183,\n",
              " 'the': 3310,\n",
              " 'last': 82,\n",
              " 'people': 87,\n",
              " \"'d\": 267,\n",
              " 'expect': 13,\n",
              " 'be': 362,\n",
              " 'involved': 5,\n",
              " 'in': 933,\n",
              " 'anything': 70,\n",
              " 'strange': 21,\n",
              " 'or': 96,\n",
              " 'mysterious': 5,\n",
              " 'because': 84,\n",
              " 'just': 161,\n",
              " 'did': 280,\n",
              " \"n't\": 826,\n",
              " 'hold': 11,\n",
              " 'with': 403,\n",
              " 'such': 21,\n",
              " 'nonsense': 4,\n",
              " 'was': 1253,\n",
              " 'director': 2,\n",
              " 'a': 1578,\n",
              " 'firm': 2,\n",
              " 'called': 44,\n",
              " 'Grunnings': 2,\n",
              " 'which': 84,\n",
              " 'made': 66,\n",
              " 'drills': 6,\n",
              " 'He': 548,\n",
              " 'big': 28,\n",
              " 'beefy': 1,\n",
              " 'man': 35,\n",
              " 'hardly': 21,\n",
              " 'any': 61,\n",
              " 'neck': 17,\n",
              " 'although': 7,\n",
              " 'he': 1208,\n",
              " 'have': 307,\n",
              " 'large': 51,\n",
              " 'mustache': 6,\n",
              " 'thin': 10,\n",
              " 'blonde': 2,\n",
              " 'had': 750,\n",
              " 'nearly': 28,\n",
              " 'twice': 14,\n",
              " 'usual': 18,\n",
              " 'amount': 1,\n",
              " 'came': 75,\n",
              " 'useful': 5,\n",
              " 'as': 484,\n",
              " 'she': 193,\n",
              " 'spent': 11,\n",
              " 'so': 186,\n",
              " 'her': 175,\n",
              " 'time': 118,\n",
              " 'craning': 2,\n",
              " 'over': 168,\n",
              " 'garden': 6,\n",
              " 'fences': 1,\n",
              " 'spying': 3,\n",
              " 'on': 618,\n",
              " 'neighbors': 2,\n",
              " 'The': 297,\n",
              " 'Dursleys': 50,\n",
              " 'small': 32,\n",
              " 'son': 9,\n",
              " 'Dudley': 138,\n",
              " 'their': 204,\n",
              " 'opinion': 5,\n",
              " 'there': 224,\n",
              " 'no': 134,\n",
              " 'finer': 2,\n",
              " 'boy': 84,\n",
              " 'anywhere': 7,\n",
              " 'everything': 28,\n",
              " 'wanted': 44,\n",
              " 'but': 373,\n",
              " 'also': 15,\n",
              " 'secret': 15,\n",
              " 'greatest': 5,\n",
              " 'fear': 8,\n",
              " 'somebody': 4,\n",
              " 'would': 151,\n",
              " 'discover': 1,\n",
              " 'it': 897,\n",
              " 'think': 121,\n",
              " 'could': 293,\n",
              " 'bear': 5,\n",
              " 'if': 198,\n",
              " 'anyone': 34,\n",
              " 'found': 68,\n",
              " 'out': 359,\n",
              " 'about': 215,\n",
              " 'Potters': 11,\n",
              " 'Potter': 99,\n",
              " \"'s\": 997,\n",
              " 'sister': 14,\n",
              " 'met': 19,\n",
              " 'for': 347,\n",
              " 'several': 12,\n",
              " 'years': 50,\n",
              " ';': 135,\n",
              " 'fact': 15,\n",
              " 'pretended': 3,\n",
              " 'good-for-nothing': 1,\n",
              " 'husband': 1,\n",
              " 'unDursleyish': 1,\n",
              " 'possible': 12,\n",
              " 'shuddered': 3,\n",
              " 'what': 263,\n",
              " 'arrived': 17,\n",
              " 'street': 21,\n",
              " 'knew': 62,\n",
              " 'too': 98,\n",
              " 'never': 111,\n",
              " 'even': 90,\n",
              " 'seen': 53,\n",
              " 'him': 494,\n",
              " 'This': 43,\n",
              " 'another': 50,\n",
              " 'good': 65,\n",
              " 'reason': 22,\n",
              " 'keeping': 10,\n",
              " 'away': 70,\n",
              " 'want': 69,\n",
              " 'mixing': 2,\n",
              " 'child': 2,\n",
              " 'like': 189,\n",
              " 'When': 38,\n",
              " 'woke': 10,\n",
              " 'up': 359,\n",
              " 'dull': 2,\n",
              " 'gray': 11,\n",
              " 'Tuesday': 3,\n",
              " 'our': 37,\n",
              " 'story': 11,\n",
              " 'starts': 3,\n",
              " 'nothing': 43,\n",
              " 'cloudy': 2,\n",
              " 'sky': 13,\n",
              " 'outside': 35,\n",
              " 'suggest': 4,\n",
              " 'things': 51,\n",
              " 'soon': 11,\n",
              " 'happening': 4,\n",
              " 'all': 346,\n",
              " 'country': 4,\n",
              " 'hummed': 3,\n",
              " 'picked': 16,\n",
              " 'his': 896,\n",
              " 'most': 27,\n",
              " 'boring': 3,\n",
              " 'tie': 1,\n",
              " 'work': 28,\n",
              " 'gossiped': 1,\n",
              " 'happily': 5,\n",
              " 'wrestled': 1,\n",
              " 'screaming': 4,\n",
              " 'into': 219,\n",
              " 'high': 34,\n",
              " 'chair': 10,\n",
              " 'None': 2,\n",
              " 'them': 323,\n",
              " 'noticed': 29,\n",
              " 'tawny': 1,\n",
              " 'owl': 41,\n",
              " 'flutter': 3,\n",
              " 'past': 43,\n",
              " 'window': 32,\n",
              " 'At': 42,\n",
              " 'half': 28,\n",
              " 'eight': 4,\n",
              " 'briefcase': 1,\n",
              " 'pecked': 1,\n",
              " 'cheek': 4,\n",
              " 'tried': 62,\n",
              " 'kiss': 3,\n",
              " 'good-bye': 5,\n",
              " 'missed': 4,\n",
              " 'now': 124,\n",
              " 'having': 14,\n",
              " 'tantrum': 3,\n",
              " 'throwing': 10,\n",
              " 'cereal': 1,\n",
              " 'at': 581,\n",
              " 'walls': 16,\n",
              " '``': 2307,\n",
              " 'Little': 4,\n",
              " 'tyke': 2,\n",
              " \"''\": 2441,\n",
              " 'chortled': 2,\n",
              " 'left': 82,\n",
              " 'house': 74,\n",
              " 'got': 192,\n",
              " 'car': 20,\n",
              " 'backed': 3,\n",
              " 'drive': 4,\n",
              " 'It': 286,\n",
              " 'corner': 25,\n",
              " 'first': 104,\n",
              " 'sign': 17,\n",
              " 'something': 121,\n",
              " 'peculiar': 4,\n",
              " '--': 787,\n",
              " 'cat': 24,\n",
              " 'reading': 5,\n",
              " 'map': 4,\n",
              " 'For': 20,\n",
              " 'second': 42,\n",
              " 'realize': 10,\n",
              " 'then': 116,\n",
              " 'jerked': 10,\n",
              " 'head': 96,\n",
              " 'around': 141,\n",
              " 'look': 101,\n",
              " 'again': 101,\n",
              " 'There': 87,\n",
              " 'tabby': 4,\n",
              " 'standing': 31,\n",
              " 'sight': 25,\n",
              " 'What': 116,\n",
              " 'been': 211,\n",
              " 'thinking': 15,\n",
              " '?': 754,\n",
              " 'must': 64,\n",
              " 'trick': 3,\n",
              " 'light': 25,\n",
              " 'blinked': 5,\n",
              " 'stared': 35,\n",
              " 'back': 258,\n",
              " 'As': 42,\n",
              " 'drove': 6,\n",
              " 'road': 7,\n",
              " 'watched': 21,\n",
              " 'mirror': 40,\n",
              " 'said': 793,\n",
              " 'looking': 96,\n",
              " 'cats': 6,\n",
              " 'read': 42,\n",
              " 'maps': 1,\n",
              " 'signs': 1,\n",
              " 'gave': 37,\n",
              " 'himself': 65,\n",
              " 'little': 67,\n",
              " 'shake': 7,\n",
              " 'put': 58,\n",
              " 'mind': 46,\n",
              " 'toward': 71,\n",
              " 'town': 5,\n",
              " 'thought': 94,\n",
              " 'except': 23,\n",
              " 'order': 3,\n",
              " 'hoping': 10,\n",
              " 'get': 183,\n",
              " 'day': 59,\n",
              " 'But': 110,\n",
              " 'edge': 11,\n",
              " 'driven': 3,\n",
              " 'by': 143,\n",
              " 'else': 38,\n",
              " 'sat': 45,\n",
              " 'morning': 31,\n",
              " 'traffic': 3,\n",
              " 'jam': 3,\n",
              " 'help': 27,\n",
              " 'noticing': 9,\n",
              " 'seemed': 72,\n",
              " 'lot': 47,\n",
              " 'strangely': 5,\n",
              " 'dressed': 7,\n",
              " 'People': 10,\n",
              " 'cloaks': 5,\n",
              " 'who': 160,\n",
              " 'funny': 23,\n",
              " 'clothes': 8,\n",
              " 'getups': 1,\n",
              " 'saw': 62,\n",
              " 'young': 9,\n",
              " '!': 474,\n",
              " 'supposed': 16,\n",
              " 'this': 205,\n",
              " 'some': 72,\n",
              " 'stupid': 19,\n",
              " 'new': 36,\n",
              " 'fashion': 2,\n",
              " 'drummed': 1,\n",
              " 'fingers': 14,\n",
              " 'steering': 2,\n",
              " 'wheel': 1,\n",
              " 'eyes': 104,\n",
              " 'fell': 46,\n",
              " 'huddle': 2,\n",
              " 'these': 33,\n",
              " 'weirdos': 2,\n",
              " 'quite': 34,\n",
              " 'close': 19,\n",
              " 'whispering': 4,\n",
              " 'excitedly': 6,\n",
              " 'together': 20,\n",
              " 'enraged': 1,\n",
              " 'see': 162,\n",
              " 'couple': 8,\n",
              " 'why': 42,\n",
              " 'older': 6,\n",
              " 'than': 93,\n",
              " 'wearing': 17,\n",
              " 'an': 200,\n",
              " 'emerald-green': 3,\n",
              " 'cloak': 57,\n",
              " 'nerve': 5,\n",
              " 'struck': 5,\n",
              " 'probably': 10,\n",
              " 'silly': 3,\n",
              " 'stunt': 1,\n",
              " 'obviously': 11,\n",
              " 'collecting': 3,\n",
              " '...': 201,\n",
              " 'yes': 26,\n",
              " 'moved': 22,\n",
              " 'few': 55,\n",
              " 'minutes': 30,\n",
              " 'later': 43,\n",
              " 'parking': 3,\n",
              " 'always': 38,\n",
              " 'office': 5,\n",
              " 'ninth': 1,\n",
              " 'floor': 48,\n",
              " 'If': 47,\n",
              " 'might': 53,\n",
              " 'harder': 6,\n",
              " 'concentrate': 3,\n",
              " 'owls': 20,\n",
              " 'swoop': 1,\n",
              " 'ing': 4,\n",
              " 'broad': 2,\n",
              " 'daylight': 5,\n",
              " 'though': 86,\n",
              " 'down': 178,\n",
              " 'pointed': 21,\n",
              " 'gazed': 1,\n",
              " 'open-': 1,\n",
              " 'mouthed': 2,\n",
              " 'after': 49,\n",
              " 'sped': 8,\n",
              " 'overhead': 6,\n",
              " 'Most': 3,\n",
              " 'nighttime': 3,\n",
              " 'however': 17,\n",
              " 'owl-free': 1,\n",
              " 'yelled': 15,\n",
              " 'five': 25,\n",
              " 'different': 18,\n",
              " 'important': 15,\n",
              " 'telephone': 6,\n",
              " 'calls': 2,\n",
              " 'shouted': 29,\n",
              " 'bit': 65,\n",
              " 'more': 108,\n",
              " 'mood': 5,\n",
              " 'until': 44,\n",
              " 'lunchtime': 2,\n",
              " 'when': 140,\n",
              " 'stretch': 1,\n",
              " 'legs': 21,\n",
              " 'walk': 12,\n",
              " 'across': 38,\n",
              " 'buy': 12,\n",
              " 'bun': 2,\n",
              " 'from': 233,\n",
              " 'bakery': 1,\n",
              " 'forgotten': 17,\n",
              " 'passed': 24,\n",
              " 'group': 2,\n",
              " 'next': 88,\n",
              " 'baker': 1,\n",
              " 'eyed': 3,\n",
              " 'angrily': 7,\n",
              " 'know': 185,\n",
              " 'uneasy': 2,\n",
              " 'bunch': 2,\n",
              " 'single': 9,\n",
              " 'tin': 1,\n",
              " 'way': 93,\n",
              " 'clutching': 7,\n",
              " 'doughnut': 1,\n",
              " 'bag': 10,\n",
              " 'caught': 38,\n",
              " 'words': 24,\n",
              " 'saying': 43,\n",
              " 'right': 110,\n",
              " 'I': 919,\n",
              " 'heard': 74,\n",
              " 'Harry': 1323,\n",
              " 'stopped': 29,\n",
              " 'dead': 23,\n",
              " 'Fear': 2,\n",
              " 'flooded': 4,\n",
              " 'looked': 169,\n",
              " 'whisperers': 1,\n",
              " 'better': 37,\n",
              " 'dashed': 3,\n",
              " 'hurried': 14,\n",
              " 'snapped': 25,\n",
              " 'secretary': 1,\n",
              " 'not': 208,\n",
              " 'disturb': 2,\n",
              " 'seized': 13,\n",
              " 'almost': 47,\n",
              " 'finished': 12,\n",
              " 'dialing': 1,\n",
              " 'home': 18,\n",
              " 'changed': 11,\n",
              " 'receiver': 1,\n",
              " 'stroked': 3,\n",
              " 'being': 38,\n",
              " 'unusual': 5,\n",
              " 'name': 46,\n",
              " 'sure': 42,\n",
              " 'lots': 7,\n",
              " 'Come': 22,\n",
              " 'nephew': 2,\n",
              " 'Harvey': 1,\n",
              " 'Or': 10,\n",
              " 'Harold': 1,\n",
              " 'point': 14,\n",
              " 'worrying': 3,\n",
              " 'upset': 5,\n",
              " 'mention': 8,\n",
              " 'blame': 4,\n",
              " 'same': 36,\n",
              " 'those': 22,\n",
              " 'afternoon': 16,\n",
              " 'building': 3,\n",
              " \"o'clock\": 11,\n",
              " 'still': 88,\n",
              " 'worried': 11,\n",
              " 'walked': 46,\n",
              " 'straight': 25,\n",
              " 'someone': 23,\n",
              " 'door': 105,\n",
              " 'Sorry': 7,\n",
              " 'grunted': 7,\n",
              " 'tiny': 14,\n",
              " 'old': 56,\n",
              " 'stumbled': 4,\n",
              " 'seconds': 15,\n",
              " 'before': 101,\n",
              " 'realized': 17,\n",
              " 'violet': 3,\n",
              " 'seem': 16,\n",
              " 'knocked': 18,\n",
              " 'ground': 34,\n",
              " 'On': 18,\n",
              " 'contrary': 2,\n",
              " 'face': 87,\n",
              " 'split': 6,\n",
              " 'wide': 12,\n",
              " 'smile': 13,\n",
              " 'squeaky': 1,\n",
              " 'voice': 59,\n",
              " 'passersby': 1,\n",
              " 'stare': 5,\n",
              " 'Do': 51,\n",
              " 'sorry': 23,\n",
              " 'my': 85,\n",
              " 'dear': 16,\n",
              " 'sir': 12,\n",
              " 'me': 213,\n",
              " 'today': 14,\n",
              " 'Rejoice': 1,\n",
              " 'You-Know-Who': 17,\n",
              " 'has': 37,\n",
              " 'gone': 49,\n",
              " 'Even': 15,\n",
              " 'Muggles': 19,\n",
              " 'yourself': 14,\n",
              " 'should': 48,\n",
              " 'celebrating': 5,\n",
              " 'happy': 12,\n",
              " 'And': 110,\n",
              " 'hugged': 3,\n",
              " 'middle': 13,\n",
              " 'off': 199,\n",
              " 'stood': 37,\n",
              " 'rooted': 2,\n",
              " 'spot': 8,\n",
              " 'complete': 4,\n",
              " 'stranger': 7,\n",
              " 'Muggle': 22,\n",
              " 'whatever': 7,\n",
              " 'rattled': 4,\n",
              " 'set': 24,\n",
              " 'imagining': 5,\n",
              " 'hoped': 4,\n",
              " 'approve': 1,\n",
              " 'imagination': 2,\n",
              " 'pulled': 51,\n",
              " 'driveway': 1,\n",
              " 'thing': 49,\n",
              " 'improve': 2,\n",
              " 'spotted': 11,\n",
              " 'sitting': 25,\n",
              " 'wall': 36,\n",
              " 'one': 231,\n",
              " 'markings': 3,\n",
              " 'its': 81,\n",
              " 'Shoo': 1,\n",
              " 'loudly': 18,\n",
              " 'move': 24,\n",
              " 'stern': 4,\n",
              " 'Was': 8,\n",
              " 'behavior': 1,\n",
              " 'wondered': 14,\n",
              " 'Trying': 1,\n",
              " 'pull': 12,\n",
              " 'let': 59,\n",
              " 'determined': 3,\n",
              " 'wife': 3,\n",
              " 'nice': 21,\n",
              " 'She': 59,\n",
              " 'told': 90,\n",
              " 'dinner': 8,\n",
              " 'Next': 8,\n",
              " 'Door': 1,\n",
              " 'problems': 4,\n",
              " 'daughter': 1,\n",
              " 'how': 90,\n",
              " 'learned': 10,\n",
              " 'word': 19,\n",
              " '(': 30,\n",
              " 'Wo': 1,\n",
              " ')': 33,\n",
              " 'act': 1,\n",
              " 'normally': 3,\n",
              " 'bed': 42,\n",
              " 'went': 71,\n",
              " 'living': 9,\n",
              " 'room': 89,\n",
              " 'catch': 23,\n",
              " 'report': 3,\n",
              " 'evening': 14,\n",
              " 'news': 9,\n",
              " ':': 69,\n",
              " 'finally': 20,\n",
              " 'bird-watchers': 1,\n",
              " 'everywhere': 4,\n",
              " 'reported': 1,\n",
              " 'nation': 1,\n",
              " 'behaving': 3,\n",
              " 'unusually': 1,\n",
              " 'Although': 4,\n",
              " 'hunt': 1,\n",
              " 'night': 47,\n",
              " 'are': 148,\n",
              " 'ever': 55,\n",
              " 'hundreds': 10,\n",
              " 'sightings': 1,\n",
              " 'birds': 5,\n",
              " 'flying': 13,\n",
              " 'every': 37,\n",
              " 'direction': 13,\n",
              " 'since': 21,\n",
              " 'sunrise': 1,\n",
              " 'Experts': 1,\n",
              " 'unable': 2,\n",
              " 'explain': 11,\n",
              " 'suddenly': 66,\n",
              " 'sleeping': 3,\n",
              " 'pattern': 1,\n",
              " 'newscaster': 1,\n",
              " 'allowed': 17,\n",
              " 'grin': 6,\n",
              " 'Jim': 2,\n",
              " 'McGuffin': 1,\n",
              " 'weather': 3,\n",
              " 'Going': 1,\n",
              " 'showers': 1,\n",
              " 'tonight': 20,\n",
              " 'Well': 59,\n",
              " 'Ted': 1,\n",
              " 'weatherman': 1,\n",
              " 'do': 260,\n",
              " 'only': 101,\n",
              " 'acting': 3,\n",
              " 'oddly': 2,\n",
              " 'Viewers': 1,\n",
              " 'far': 22,\n",
              " 'apart': 13,\n",
              " 'Kent': 2,\n",
              " 'Yorkshire': 2,\n",
              " 'Dundee': 1,\n",
              " 'phoning': 1,\n",
              " 'tell': 65,\n",
              " 'instead': 14,\n",
              " 'rain': 4,\n",
              " 'promised': 3,\n",
              " 'yesterday': 6,\n",
              " \"'ve\": 179,\n",
              " 'downpour': 1,\n",
              " 'shooting': 4,\n",
              " 'stars': 9,\n",
              " 'Perhaps': 11,\n",
              " 'Bonfire': 1,\n",
              " 'Night': 1,\n",
              " 'early': 4,\n",
              " 'week': 24,\n",
              " 'folks': 1,\n",
              " 'can': 76,\n",
              " 'promise': 2,\n",
              " 'wet': 4,\n",
              " 'frozen': 2,\n",
              " 'armchair': 3,\n",
              " 'Shooting': 2,\n",
              " 'Britain': 3,\n",
              " 'Owls': 3,\n",
              " 'Mysterious': 1,\n",
              " 'place': 34,\n",
              " 'whisper': 8,\n",
              " 'carrying': 9,\n",
              " 'two': 77,\n",
              " 'cups': 1,\n",
              " 'tea': 14,\n",
              " 'cleared': 6,\n",
              " 'throat': 5,\n",
              " 'nervously': 11,\n",
              " 'Er': 12,\n",
              " 'Petunia': 57,\n",
              " 'your': 134,\n",
              " 'lately': 3,\n",
              " 'expected': 12,\n",
              " 'shocked': 7,\n",
              " 'angry': 15,\n",
              " 'After': 19,\n",
              " 'No': 61,\n",
              " 'sharply': 7,\n",
              " 'Why': 25,\n",
              " 'Funny': 4,\n",
              " 'stuff': 15,\n",
              " 'mumbled': 5,\n",
              " 'funny-looking': 1,\n",
              " 'So': 51,\n",
              " 'maybe': 11,\n",
              " 'crowd': 17,\n",
              " 'sipped': 1,\n",
              " 'through': 119,\n",
              " 'pursed': 1,\n",
              " 'lips': 9,\n",
              " 'whether': 9,\n",
              " 'dared': 3,\n",
              " 'decided': 11,\n",
              " 'dare': 11,\n",
              " 'Instead': 2,\n",
              " 'casually': 4,\n",
              " 'Their': 12,\n",
              " 'age': 5,\n",
              " 'suppose': 29,\n",
              " 'stiffly': 3,\n",
              " 'Howard': 1,\n",
              " 'is': 186,\n",
              " 'Nasty': 1,\n",
              " 'common': 22,\n",
              " 'ask': 33,\n",
              " 'Oh': 60,\n",
              " 'heart': 24,\n",
              " 'sinking': 2,\n",
              " 'horribly': 2,\n",
              " 'Yes': 42,\n",
              " 'agree': 2,\n",
              " 'subject': 3,\n",
              " 'upstairs': 13,\n",
              " 'While': 8,\n",
              " 'bathroom': 5,\n",
              " 'crept': 11,\n",
              " 'bedroom': 5,\n",
              " 'peered': 7,\n",
              " 'front': 51,\n",
              " 'staring': 23,\n",
              " 'waiting': 19,\n",
              " 'Could': 10,\n",
              " 'related': 1,\n",
              " 'pair': 16,\n",
              " 'well': 47,\n",
              " 'asleep': 21,\n",
              " 'quickly': 44,\n",
              " 'lay': 17,\n",
              " 'awake': 7,\n",
              " 'turning': 15,\n",
              " 'His': 41,\n",
              " 'comforting': 2,\n",
              " 'come': 72,\n",
              " 'near': 16,\n",
              " 'kind': 10,\n",
              " '....': 67,\n",
              " 'mixed': 4,\n",
              " 'going': 134,\n",
              " 'yawned': 2,\n",
              " 'turned': 77,\n",
              " 'affect': 1,\n",
              " 'How': 47,\n",
              " 'wrong': 18,\n",
              " 'drifting': 1,\n",
              " 'sleep': 17,\n",
              " 'showing': 7,\n",
              " 'sleepiness': 1,\n",
              " 'statue': 4,\n",
              " 'fixed': 6,\n",
              " 'unblinkingly': 2,\n",
              " 'quiver': 3,\n",
              " 'slammed': 7,\n",
              " 'nor': 6,\n",
              " 'swooped': 7,\n",
              " 'In': 31,\n",
              " 'midnight': 7,\n",
              " 'A': 110,\n",
              " 'appeared': 12,\n",
              " 'watching': 18,\n",
              " 'silently': 7,\n",
              " 'popped': 2,\n",
              " 'tail': 14,\n",
              " 'twitched': 5,\n",
              " 'narrowed': 2,\n",
              " 'Nothing': 11,\n",
              " 'tall': 12,\n",
              " 'judging': 1,\n",
              " 'silver': 31,\n",
              " 'hair': 37,\n",
              " 'beard': 12,\n",
              " 'both': 29,\n",
              " 'long': 71,\n",
              " 'enough': 47,\n",
              " 'tuck': 1,\n",
              " 'belt': 1,\n",
              " 'robes': 25,\n",
              " 'purple': 13,\n",
              " 'swept': 2,\n",
              " 'high-heeled': 1,\n",
              " 'buckled': 1,\n",
              " 'boots': 5,\n",
              " 'blue': 11,\n",
              " 'bright': 16,\n",
              " 'sparkling': 4,\n",
              " 'behind': 74,\n",
              " 'half-moon': 2,\n",
              " 'spectacles': 2,\n",
              " 'nose': 31,\n",
              " 'crooked': 2,\n",
              " 'broken': 11,\n",
              " 'least': 11,\n",
              " 'Albus': 9,\n",
              " 'Dumbledore': 156,\n",
              " 'where': 85,\n",
              " 'unwelcome': 1,\n",
              " 'busy': 10,\n",
              " 'rummaging': 2,\n",
              " 'other': 88,\n",
              " 'end': 47,\n",
              " 'amuse': 2,\n",
              " 'chuckled': 7,\n",
              " 'muttered': 20,\n",
              " 'known': 11,\n",
              " 'inside': 54,\n",
              " 'pocket': 17,\n",
              " 'cigarette': 1,\n",
              " 'lighter': 2,\n",
              " 'flicked': 3,\n",
              " 'open': 55,\n",
              " 'held': 21,\n",
              " 'air': 47,\n",
              " 'clicked': 7,\n",
              " 'nearest': 6,\n",
              " 'lamp': 15,\n",
              " 'pop': 5,\n",
              " 'flickered': 2,\n",
              " 'darkness': 7,\n",
              " 'Twelve': 2,\n",
              " 'times': 18,\n",
              " 'Put-Outer': 3,\n",
              " 'lights': 4,\n",
              " 'whole': 33,\n",
              " 'pinpricks': 1,\n",
              " 'distance': 4,\n",
              " 'beady-eyed': 1,\n",
              " 'able': 26,\n",
              " 'pavement': 1,\n",
              " 'slipped': 10,\n",
              " 'moment': 47,\n",
              " 'spoke': 19,\n",
              " 'Fancy': 1,\n",
              " 'seeing': 3,\n",
              " 'here': 110,\n",
              " 'Professor': 180,\n",
              " 'McGonagall': 101,\n",
              " 'smiling': 19,\n",
              " 'rather': 22,\n",
              " 'severe-looking': 1,\n",
              " 'woman': 18,\n",
              " 'square': 2,\n",
              " 'glasses': 15,\n",
              " 'exactly': 19,\n",
              " 'shape': 3,\n",
              " 'emerald': 3,\n",
              " 'Her': 4,\n",
              " 'black': 47,\n",
              " 'drawn': 2,\n",
              " 'tight': 8,\n",
              " 'distinctly': 1,\n",
              " 'ruffled': 3,\n",
              " 'asked': 59,\n",
              " 'My': 20,\n",
              " 'sit': 17,\n",
              " 'You': 163,\n",
              " 'stiff': 2,\n",
              " 'brick': 3,\n",
              " 'All': 48,\n",
              " 'dozen': 3,\n",
              " 'feasts': 2,\n",
              " 'parties': 2,\n",
              " 'sniffed': 4,\n",
              " 'everyone': 40,\n",
              " 'impatiently': 3,\n",
              " 'careful': 10,\n",
              " \"'\": 353,\n",
              " 'dark': 44,\n",
              " 'living-room': 1,\n",
              " 'Flocks': 1,\n",
              " \"'re\": 136,\n",
              " 'completely': 6,\n",
              " 'bound': 4,\n",
              " 'notice': 8,\n",
              " \"'ll\": 161,\n",
              " 'bet': 14,\n",
              " 'Dedalus': 4,\n",
              " 'Diggle': 5,\n",
              " 'sense': 4,\n",
              " 'ca': 51,\n",
              " 'gently': 6,\n",
              " 'We': 77,\n",
              " 'precious': 2,\n",
              " 'celebrate': 2,\n",
              " 'eleven': 14,\n",
              " 'irritably': 3,\n",
              " 'lose': 13,\n",
              " 'heads': 18,\n",
              " 'downright': 2,\n",
              " 'careless': 2,\n",
              " 'streets': 2,\n",
              " 'swapping': 1,\n",
              " 'rumors': 3,\n",
              " 'threw': 17,\n",
              " 'sharp': 11,\n",
              " 'sideways': 4,\n",
              " 'glance': 3,\n",
              " 'fine': 5,\n",
              " 'YouKnow-Who': 1,\n",
              " 'seems': 7,\n",
              " 'disappeared': 16,\n",
              " 'us': 81,\n",
              " 'really': 70,\n",
              " 'certainly': 7,\n",
              " 'thankful': 1,\n",
              " 'Would': 5,\n",
              " 'care': 8,\n",
              " 'lemon': 7,\n",
              " 'drop': 8,\n",
              " 'sweet': 4,\n",
              " \"'m\": 122,\n",
              " 'fond': 2,\n",
              " 'coldly': 4,\n",
              " 'drops': 3,\n",
              " '-': 35,\n",
              " 'surely': 2,\n",
              " 'sensible': 1,\n",
              " 'person': 8,\n",
              " 'call': 17,\n",
              " \"'You-\": 1,\n",
              " 'Know-Who': 2,\n",
              " 'trying': 63,\n",
              " 'persuade': 2,\n",
              " 'proper': 5,\n",
              " 'Voldemort': 36,\n",
              " 'flinched': 1,\n",
              " 'unsticking': 1,\n",
              " 'gets': 9,\n",
              " 'confusing': 2,\n",
              " 'we': 192,\n",
              " 'keep': 50,\n",
              " \"'You-Know-Who\": 1,\n",
              " 'frightened': 5,\n",
              " 'haven': 1,\n",
              " \"'t\": 2,\n",
              " 'sounding': 7,\n",
              " 'exasperated': 1,\n",
              " 'admiring': 3,\n",
              " 'Everyone': 20,\n",
              " 'knows': 20,\n",
              " 'You-Know-': 2,\n",
              " 'oh': 7,\n",
              " 'flatter': 1,\n",
              " 'calmly': 3,\n",
              " 'powers': 3,\n",
              " 'will': 85,\n",
              " 'Only': 10,\n",
              " 'noble': 2,\n",
              " 'use': 20,\n",
              " 'lucky': 13,\n",
              " 'blushed': 2,\n",
              " 'Madam': 36,\n",
              " 'Pomfrey': 13,\n",
              " 'liked': 14,\n",
              " 'earmuffs': 1,\n",
              " 'shot': 11,\n",
              " 'About': 9,\n",
              " 'reached': 37,\n",
              " 'anxious': 2,\n",
              " 'discuss': 1,\n",
              " 'real': 12,\n",
              " 'cold': 24,\n",
              " 'hard': 29,\n",
              " 'neither': 7,\n",
              " 'piercing': 4,\n",
              " 'plain': 3,\n",
              " 'believe': 21,\n",
              " 'true': 12,\n",
              " 'choosing': 2,\n",
              " 'answer': 22,\n",
              " 'pressed': 7,\n",
              " 'Godric': 1,\n",
              " 'Hollow': 1,\n",
              " 'find': 53,\n",
              " 'rumor': 1,\n",
              " 'Lily': 7,\n",
              " 'James': 5,\n",
              " '“': 11,\n",
              " 'bowed': 9,\n",
              " 'gasped': 20,\n",
              " 'patted': 2,\n",
              " 'shoulder': 15,\n",
              " 'heavily': 4,\n",
              " 'trembled': 3,\n",
              " 'That': 52,\n",
              " 'kill': 18,\n",
              " 'power': 10,\n",
              " 'somehow': 12,\n",
              " 'broke': 11,\n",
              " 'nodded': 10,\n",
              " 'glumly': 1,\n",
              " 'faltered': 1,\n",
              " 'done': 44,\n",
              " 'killed': 14,\n",
              " 'astounding': 1,\n",
              " 'stop': 39,\n",
              " 'heaven': 1,\n",
              " 'survive': 1,\n",
              " 'guess': 3,\n",
              " 'may': 10,\n",
              " 'lace': 1,\n",
              " 'handkerchief': 5,\n",
              " 'dabbed': 1,\n",
              " 'beneath': 6,\n",
              " 'great': 45,\n",
              " 'sniff': 1,\n",
              " 'took': 62,\n",
              " 'golden': 7,\n",
              " 'watch': 18,\n",
              " 'examined': 3,\n",
              " 'odd': 13,\n",
              " 'twelve': 14,\n",
              " 'hands': 34,\n",
              " 'numbers': 2,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.tokenize.word_tokenize(nltk_sentences[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YUzmcToJY6V",
        "outputId": "ad1b8630-b326-47cf-8900-9d4ac4baf026"
      },
      "id": "7YUzmcToJY6V",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CHAPTER',\n",
              " 'ONE',\n",
              " 'THE',\n",
              " 'BOY',\n",
              " 'WHO',\n",
              " 'LIVED',\n",
              " 'Mr.',\n",
              " 'and',\n",
              " 'Mrs.',\n",
              " 'Dursley',\n",
              " ',',\n",
              " 'of',\n",
              " 'number',\n",
              " 'four',\n",
              " ',',\n",
              " 'Privet',\n",
              " 'Drive',\n",
              " ',',\n",
              " 'were',\n",
              " 'proud',\n",
              " 'to',\n",
              " 'say',\n",
              " 'that',\n",
              " 'they',\n",
              " 'were',\n",
              " 'perfectly',\n",
              " 'normal',\n",
              " ',',\n",
              " 'thank',\n",
              " 'you',\n",
              " 'very',\n",
              " 'much',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = {}\n",
        "for t in doc:\n",
        "  if t.text not in tokens:\n",
        "    tokens[t.text] = 0\n",
        "  tokens[t.text] +=1\n",
        "\n",
        "frequent_tokens = sorted(tokens, key=tokens.get, reverse=True) [:20]\n",
        "for t in frequent_tokens:\n",
        "  print(t.replace(\"\\n\",\"<NEWLINE>\"),\"\\t\\t\\t\\t\", tokens[t])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aORg40NBLBnS",
        "outputId": "41727ec7-d607-4ebf-a95b-7bf530358ad1"
      },
      "id": "aORg40NBLBnS",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ", \t\t\t\t 5658\n",
            ". \t\t\t\t 5125\n",
            "\" \t\t\t\t 4747\n",
            "the \t\t\t\t 3312\n",
            "<NEWLINE><NEWLINE> \t\t\t\t 3014\n",
            "to \t\t\t\t 1851\n",
            "and \t\t\t\t 1807\n",
            "a \t\t\t\t 1581\n",
            "Harry \t\t\t\t 1324\n",
            "was \t\t\t\t 1253\n",
            "of \t\t\t\t 1250\n",
            "he \t\t\t\t 1208\n",
            "'s \t\t\t\t 998\n",
            "in \t\t\t\t 935\n",
            "I \t\t\t\t 922\n",
            "it \t\t\t\t 898\n",
            "his \t\t\t\t 896\n",
            "you \t\t\t\t 838\n",
            "n't \t\t\t\t 821\n",
            "said \t\t\t\t 793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#N-Gram Computation"
      ],
      "metadata": {
        "id": "fVWy4riJMHPE"
      },
      "id": "fVWy4riJMHPE"
    },
    {
      "cell_type": "code",
      "source": [
        "nltk_sentence = nltk_sentences[80]\n",
        "sentence_tokens = nltk.tokenize.word_tokenize(nltk_sentence)\n",
        "ngrams = list(nltk.ngrams(sentence_tokens , 2 ))\n",
        "print(nltk_sentence)\n",
        "ngrams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lk3PAiOTMKAs",
        "outputId": "839c5307-5c52-4a04-c145-67662db7dbe9"
      },
      "id": "lk3PAiOTMKAs",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It was now sitting on his garden wall.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('It', 'was'),\n",
              " ('was', 'now'),\n",
              " ('now', 'sitting'),\n",
              " ('sitting', 'on'),\n",
              " ('on', 'his'),\n",
              " ('his', 'garden'),\n",
              " ('garden', 'wall'),\n",
              " ('wall', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spacy_sentence=spacy_sentences[100]\n",
        "sentence_doc = nlp(spacy_sentence.text)\n",
        "ngrams = list(textacy.extract.basics.ngrams(sentence_doc,2,filter_stops = False))\n",
        "print(spacy_sentence)\n",
        "ngrams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sWummkzMxeW",
        "outputId": "701ba7af-0e91-4fd4-d244-2154f1f68b65"
      },
      "id": "5sWummkzMxeW",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "And now, over to Jim McGuffin with the weather.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[And now, over to, to Jim, Jim McGuffin, McGuffin with, with the, the weather]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#POS Tagging"
      ],
      "metadata": {
        "id": "uQHCdqIrN0fx"
      },
      "id": "uQHCdqIrN0fx"
    },
    {
      "cell_type": "code",
      "source": [
        "print(nltk_sentence)\n",
        "pos_tags = nltk.pos_tag(sentence_tokens)\n",
        "for t, tag in pos_tags:\n",
        "  print(t,\"\\t\\t\",tag)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Heu5BWS5N3I9",
        "outputId": "8d7ccb92-8c18-4fb0-e686-3fa4b347b81d"
      },
      "id": "Heu5BWS5N3I9",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It was now sitting on his garden wall.\n",
            "It \t\t PRP\n",
            "was \t\t VBD\n",
            "now \t\t RB\n",
            "sitting \t\t VBG\n",
            "on \t\t IN\n",
            "his \t\t PRP$\n",
            "garden \t\t NN\n",
            "wall \t\t NN\n",
            ". \t\t .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(spacy_sentence)\n",
        "for t in sentence_doc:\n",
        "  print(t.text,\"\\t\\t\",t.pos_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jje551jSOFqz",
        "outputId": "ed1b689a-c41c-4f1b-d439-4255d99589a3"
      },
      "id": "jje551jSOFqz",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "And now, over to Jim McGuffin with the weather.\n",
            "And \t\t CCONJ\n",
            "now \t\t ADV\n",
            ", \t\t PUNCT\n",
            "over \t\t ADP\n",
            "to \t\t ADP\n",
            "Jim \t\t PROPN\n",
            "McGuffin \t\t PROPN\n",
            "with \t\t ADP\n",
            "the \t\t DET\n",
            "weather \t\t NOUN\n",
            ". \t\t PUNCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Stemming"
      ],
      "metadata": {
        "id": "VAQjLliHOvY7"
      },
      "id": "VAQjLliHOvY7"
    },
    {
      "cell_type": "code",
      "source": [
        "print(nltk_sentence)\n",
        "porter = nltk.stem.PorterStemmer()\n",
        "for t in sentence_tokens:\n",
        "  print(t,\"\\t\\t\",porter.stem(t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Njc6VIcgOw-O",
        "outputId": "0ea3e99b-c1d2-4540-f2bc-c24d7bbdcdb4"
      },
      "id": "Njc6VIcgOw-O",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It was now sitting on his garden wall.\n",
            "It \t\t it\n",
            "was \t\t wa\n",
            "now \t\t now\n",
            "sitting \t\t sit\n",
            "on \t\t on\n",
            "his \t\t hi\n",
            "garden \t\t garden\n",
            "wall \t\t wall\n",
            ". \t\t .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lemmatization"
      ],
      "metadata": {
        "id": "HdSY1nM8PLzK"
      },
      "id": "HdSY1nM8PLzK"
    },
    {
      "cell_type": "code",
      "source": [
        "print(nltk_sentence)\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "for t in sentence_tokens:\n",
        "  print(t,\"\\t\\t\", lemmatizer.lemmatize(t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yp4Dxma7POs3",
        "outputId": "0f74c6d9-44ad-43d3-eb09-b8475b7f8d24"
      },
      "id": "Yp4Dxma7POs3",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It was now sitting on his garden wall.\n",
            "It \t\t It\n",
            "was \t\t wa\n",
            "now \t\t now\n",
            "sitting \t\t sitting\n",
            "on \t\t on\n",
            "his \t\t his\n",
            "garden \t\t garden\n",
            "wall \t\t wall\n",
            ". \t\t .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(spacy_sentence)\n",
        "for t in sentence_doc:\n",
        "  print(t.text,\"\\t\\t\",t.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCyV8SBOPYiI",
        "outputId": "51005546-07c5-4810-90ed-5c5e73dc2ed2"
      },
      "id": "sCyV8SBOPYiI",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "And now, over to Jim McGuffin with the weather.\n",
            "And \t\t and\n",
            "now \t\t now\n",
            ", \t\t ,\n",
            "over \t\t over\n",
            "to \t\t to\n",
            "Jim \t\t Jim\n",
            "McGuffin \t\t McGuffin\n",
            "with \t\t with\n",
            "the \t\t the\n",
            "weather \t\t weather\n",
            ". \t\t .\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}